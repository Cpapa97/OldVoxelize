{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipyvolume.pylab as p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting cpapadop@10.28.0.34:3306\n"
     ]
    }
   ],
   "source": [
    "ta3p100 = dj.create_virtual_module('ta3p100', 'microns_ta3p100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetched_mesh = (ta3p100.Mesh & ta3p100.CurrentSegmentation & 'segment_id=648518346341351503').fetch1()\n",
    "# fetched_mesh = ta3p100.Decimation35.fetch(limit=1, as_dict=True)[0]\n",
    "fetched_mesh = (ta3p100.Mesh & ta3p100.CurrentSegmentation & 'segment_id=648518346341366885').fetch1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mesh:\n",
    "    def __init__(self, vertices, triangles=None):\n",
    "        self._vertices = vertices#.copy()\n",
    "        self._triangles = triangles#.copy()\n",
    "    \n",
    "    class VoxelStruct:\n",
    "        def __init__(self, origin, side_length, offset_vectors=None, voxel_vertices=None):\n",
    "            \"\"\"\n",
    "            :param origin: The starting location of which the voxels will be offset from.\n",
    "            :param side_length: The length of a side of a voxel (they are cubes).\n",
    "            :param offset_vectors: The structure that stores the locations of the voxels as offset integers from the origin (using the side length as the increment).\n",
    "            \"\"\"\n",
    "            self.origin = origin\n",
    "            self.side_length = side_length\n",
    "            if offset_vectors is not None:\n",
    "                self.offset_vectors = offset_vectors\n",
    "            if voxel_vertices is not None:\n",
    "                self.voxel_vertices = voxel_vertices\n",
    "\n",
    "        @property\n",
    "        def origin(self):\n",
    "            return np.array((self._x, self._y, self._z))\n",
    "\n",
    "        @origin.setter\n",
    "        def origin(self, coordinate):\n",
    "            self._x, self._y, self._z = coordinate\n",
    "\n",
    "        @property\n",
    "        def side_length(self):\n",
    "            return self._side_length\n",
    "\n",
    "        @side_length.setter\n",
    "        def side_length(self, side_length):\n",
    "            self._side_length = side_length\n",
    "\n",
    "        @property\n",
    "        def offset_vectors(self):\n",
    "            return self._offset_vectors\n",
    "\n",
    "        @offset_vectors.setter\n",
    "        def offset_vectors(self, offset_vectors):\n",
    "            if offset_vectors.shape == (len(offset_vectors), 3):\n",
    "                self._offset_vectors = offset_vectors\n",
    "            else:\n",
    "                raise TypeError(\"Array shape is incorrect, should be equivalent to (-1, 3).\")\n",
    "                \n",
    "        @property\n",
    "        def offset_to_bboxes(self):\n",
    "            voxel_min = self.origin + (self.offset_vectors * self.side_length)\n",
    "            voxel_max = voxel_min + self.side_length\n",
    "            return np.stack([voxel_min, voxel_max], axis=2)\n",
    "        \n",
    "        @property\n",
    "        def voxel_bboxes_to_drawable(self):\n",
    "            return self.offset_to_bboxes[:, np.arange(3), self._rectangular_idx.T].transpose(0, 2, 1)\n",
    "\n",
    "        # Maybe I should make this search_by_offset pretty extensible by some design? Like allow you to easily search by a bunch of x offsets,\n",
    "        # or even all of them. And also still be able to search for a certain offset like (0, 37, 20). Basically be able to search for a row,\n",
    "        # or from a column or a bunch of columns or for a bunch of rows, etc.\n",
    "\n",
    "        #     def search_by_offset(self, x_offset, y_offset, z_offset):\n",
    "        #         return np.where((vs.offset_vectors==(x_offset, y_offset, z_offset)).all(axis=1))[0]\n",
    "        def search_by_offset(self, key):\n",
    "            print(type(self.offset_vectors==key))\n",
    "            return np.where((self.offset_vectors==key).all(axis=1))[0]\n",
    "    \n",
    "    @property\n",
    "    def voxels(self):\n",
    "        return self._voxels\n",
    "    \n",
    "    @voxels.setter\n",
    "    def voxels(self, voxels):\n",
    "#         if voxels is self.VoxelStruct:\n",
    "        self._voxels = voxels\n",
    "#         else:\n",
    "#             raise TypeError(\"Wrong type yo, make it a VoxelStruct object.\")\n",
    "    \n",
    "    @property\n",
    "    def vertices(self):\n",
    "        return self._vertices\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_bbox(vertices):\n",
    "        return np.array([(np.min(axis), np.max(axis)) for axis in vertices.T])\n",
    "        \n",
    "    @property\n",
    "    def bbox(self):\n",
    "        return self.get_bbox(self.vertices)\n",
    "    \n",
    "    @property\n",
    "    def _rectangular_idx(self):\n",
    "        X = [0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
    "        Y = [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0]\n",
    "        Z = [0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0]\n",
    "        return np.vstack((X, Y, Z))\n",
    "    \n",
    "    @property\n",
    "    def voxels_to_bboxes(self):\n",
    "        voxels = self.voxels\n",
    "        voxel_min = voxels.origin + (voxels.offset_vectors * voxels.side_length)\n",
    "        voxel_max = voxel_min + voxels.side_length\n",
    "        return np.stack([voxel_min, voxel_max], axis=2)\n",
    "    \n",
    "    @property\n",
    "    def voxel_bboxes_to_drawable(self):\n",
    "        return self.voxels_to_bboxes[:, np.arange(3), self._rectangular_idx.T].transpose(0, 2, 1)\n",
    "    \n",
    "    @property\n",
    "    def volume(self):\n",
    "        \"\"\"\n",
    "        Returns the estimation of volume based on the voxelization. Units are the same as the vertex input.\n",
    "        \"\"\"\n",
    "        return self.offset**3 * len(self.structure)\n",
    "    \n",
    "    # Could have a more configurable plotting function. Like you give the argument ['mesh', 'offset_vectors', 'mesh_bbox', etc.]\n",
    "    def plot_voxels(self, voxel_count_offset=0, voxel_limit=None, use_centroids_instead=False, width=800, height=600):\n",
    "        p3.figure(width=width, height=height)\n",
    "        p3.plot_trisurf(*fetched_mesh['vertices'].T/1000, triangles=fetched_mesh['triangles'])#[:10000])\n",
    "        if use_centroids_instead:\n",
    "            centroids = mesh.structure_to_bboxes.mean(axis=2)\n",
    "            if voxel_limit is not None:\n",
    "                centroids = centroids[:1000]\n",
    "            p3.scatter(*centroids.T/1000, color='blue', marker='sphere', size=0.25)\n",
    "        else:\n",
    "            # Make it so voxel_limit can be larger \n",
    "            bboxes = self.voxel_bboxes_to_drawable\n",
    "            voxel_count = len(bboxes)\n",
    "            if voxel_count_offset >= voxel_count:\n",
    "                voxel_count_offset = voxel_count - 1\n",
    "            if voxel_limit is not None:\n",
    "                if voxel_limit < (voxel_count + voxel_count_offset):\n",
    "                    bboxes = bboxes[voxel_count_offset:voxel_count_offset+voxel_limit]\n",
    "                else:\n",
    "                    bboxes = bboxes[voxel_count_offset:]\n",
    "            for bbox in self.voxel_bboxes_to_drawable:\n",
    "                p3.plot(*bbox/1000, color='blue')\n",
    "        # Can make xyzlim stuck to the bboxes that are actually plotted.\n",
    "        p3.squarelim()\n",
    "        p3.show()\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def _sort_vertex_rows(vertices):\n",
    "#         # This still might be slower.\n",
    "#         a = vertices\n",
    "#         a = a[a[:,2].argsort()] # First sort doesn't need to be stable.\n",
    "#         a = a[a[:,1].argsort(kind='mergesort')]\n",
    "#         a = a[a[:,0].argsort(kind='mergesort')]\n",
    "#         return a\n",
    "    \n",
    "#     def create_voxels_struct_only(self, vertices, edges, sort_axis):\n",
    "#         sorted_verts = vertices[vertices[:,sort_axis].argsort()]\n",
    "#         offset_idx = np.unique(edges[1:].searchsorted(sorted_verts).T[sort_axis])\n",
    "#         return offset_idx\n",
    "    \n",
    "    def apply_split(self, vertices, edges, sort_axis):\n",
    "        \"\"\"\n",
    "        :param vertices: The vertices to sort through and split.\n",
    "        :param edges: The edges along which to split the array.\n",
    "        :param sort_axis: The axis to sort and split the array with.\n",
    "        \"\"\"\n",
    "#         sorted_verts = vertices[vertices[:,sort_axis].argsort()]\n",
    "#         splitter = sorted_verts[:,sort_axis].searchsorted(edges)\n",
    "        \n",
    "# #         uni, ind, cou = np.unique(splitter, return_index=True, return_counts=True)\n",
    "# #         if cou[0] > 1:\n",
    "# #             mask = np.where((ind>0)&(ind<len(splitter)))\n",
    "# #             offset_idx = ind[mask]\n",
    "# #             filtered = uni[mask]\n",
    "# #         else:\n",
    "# #             mask = np.where(ind<len(splitter))\n",
    "# #             offset_idx = ind[mask]\n",
    "# #             filtered = uni[np.where((ind>0)&(ind<len(splitter)))]\n",
    "        \n",
    "# #         offset_idx = np.where((splitter>0)&(splitter<len(sorted_verts)))[0]\n",
    "# #         filtered = np.unique(splitter[offset_idx])\n",
    "# #         if len(offset_idx) == len(filtered) + 2:\n",
    "# #             offset_idx = offset_idx[1:]\n",
    "# #         elif len(offset_idx) == len(filtered):\n",
    "# #             offset_idx = np.insert(offset_idx, 0, 0)\n",
    "        \n",
    "# #         unique_split, offset_idx = np.unique(splitter, return_index=True)\n",
    "# #         filtered = unique_split[(unique_split>0)&(unique_split<len(sorted_verts))]\n",
    "# #         print(len(offset_idx), len(filtered))\n",
    "# #         if len(offset_idx) == len(filtered) + 2:\n",
    "# #             offset_idx = offset_idx[1:]\n",
    "# #         elif len(filtered) == 0:\n",
    "# #             offset_idx = np.delete(offset_idx, 0)\n",
    "        \n",
    "#         unique_split, offset_idx = np.unique(splitter, return_index=True)\n",
    "#         filtered = unique_split[(unique_split>0)&(unique_split<len(sorted_verts))]\n",
    "#         if len(offset_idx) == len(filtered) + 2:\n",
    "#             offset_idx = offset_idx[1:]\n",
    "        \n",
    "#         return offset_idx, np.array(np.split(sorted_verts, filtered))\n",
    "    \n",
    "        sorted_verts = vertices[vertices[:,sort_axis].argsort()]\n",
    "        splitter = sorted_verts[:,sort_axis].searchsorted(edges)\n",
    "        split = np.array(np.split(sorted_verts, splitter)[1:])\n",
    "        offset_idx = [i for i, block in enumerate(split) if len(block) > 0]\n",
    "        # This commented out portion is actually slower, and doesn't seem to work if the voxel size is too small.\n",
    "#         offset_idx = np.unique(edges[1:].searchsorted(sorted_verts).T[sort_axis])\n",
    "        return np.array((offset_idx, split[offset_idx]))\n",
    "                \n",
    "    # Going to look to redo the CubeVoxelize method for speed and clarity.\n",
    "    def voxelize(self, side_length): # Probably need to have the side_length only be set once. Maybe just have the Voxelization class do it all in the intialization.\n",
    "        self._offset = side_length\n",
    "        bbox = self.bbox\n",
    "        # Get the number of voxels to be used to create cubes (allowing for pushing past the boundaries).\n",
    "        num_voxels = np.ceil((np.abs(np.subtract(*bbox.T) / side_length))).astype(int)\n",
    "        \n",
    "        # Create the cube voxel grid split structure. Could also sort the vertices according to the grid at this point?\n",
    "        start_coord = bbox.T[0]\n",
    "        cube_friendly_bbox = np.vstack((start_coord, start_coord + (num_voxels * side_length))).T\n",
    "#         cube_friendly_bbox = np.vstack((start_coord, start_coord + (num_voxels * side_length) + 1)).T\n",
    "        x_edges, y_edges, z_edges = [np.arange(minimum, maximum, side_length) for minimum, maximum in cube_friendly_bbox]\n",
    "        self.cube_friendly_bbox = cube_friendly_bbox # Don't actually need this as a class variable\n",
    "        self.x_edges, self.y_edges, self.z_edges = x_edges, y_edges, z_edges # Don't actually need this as a class variable\n",
    "#         print([len(x_edges), len(y_edges), len(z_edges)])        \n",
    "        \n",
    "        offset_vectors = list()\n",
    "        voxel_vertices = dict()\n",
    "        \n",
    "        # HOW do I recover the voxel indexes though? Because that's all I care about... Do I just literally only use split and just keep indexing?\n",
    "        # how do I deal with the getting the correct y_offset indices from inside an x_split?\n",
    "        \n",
    "        # Need to do the initial sort on the x_axis\n",
    "        x_split = np.array(self.apply_split(self.vertices, x_edges, 0)).T\n",
    "        for x_id, x_block in x_split:\n",
    "            y_split = np.array(self.apply_split(x_block, y_edges, 1)).T\n",
    "            \n",
    "            for y_id, y_block in y_split:\n",
    "                z_split = np.array(self.apply_split(y_block, z_edges, 2)).T\n",
    "\n",
    "                for z_id, z_block in z_split:\n",
    "                    key = (x_id, y_id, z_id)\n",
    "                    offset_vectors.append(key)\n",
    "                    voxel_vertices[key] = z_block\n",
    "\n",
    "        offset_vectors = np.array(offset_vectors)\n",
    "        self.voxels = self.VoxelStruct(self.bbox[:,0], side_length, offset_vectors, voxel_vertices)\n",
    "        \n",
    "        return offset_vectors, voxel_vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = Mesh(fetched_mesh['vertices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2434\n",
      "CPU times: user 250 ms, sys: 3.01 ms, total: 253 ms\n",
      "Wall time: 251 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectors, vox_verts = self.voxelize(side_length=2500)\n",
    "print(len(vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f0668d86314482d9c2e7ad2010e9dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "self.plot_voxels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "examp_1 = self.vertices, self.x_edges, 0\n",
    "examp_2 = x_block, y_edges, 1\n",
    "examp_3 = y_block, z_edges, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_split(vertices, edges, sort_axis):\n",
    "    sorted_verts = vertices[vertices[:,sort_axis].argsort()]\n",
    "    offset_idx = np.unique(edges[1:].searchsorted(sorted_verts).T[sort_axis])\n",
    "#     print(offset_idx)\n",
    "    splitter = sorted_verts[:,sort_axis].searchsorted(edges[1:])\n",
    "#     print(len(splitter), splitter)\n",
    "    split = np.array(np.split(sorted_verts, splitter))#offset_idx))\n",
    "#     print(split[offset_idx])\n",
    "#     offset_idx = np.unique(edges.searchsorted(sorted_verts).T[sort_axis][1:]) - 1\n",
    "#     print(offset_idx)\n",
    "#     offset_idx = [i for i, block in enumerate(split) if len(block) > 0]\n",
    "#     print(offset_idx)\n",
    "#     print(split.shape)\n",
    "    return np.array((offset_idx, split[offset_idx]))\n",
    "#     np.where(split.)\n",
    "#     return np.array([(i, block) for i, block in enumerate(split) if len(block) > 0])\n",
    "    \n",
    "#     # offset_idx = np.where((splitter>0)&(splitter<len(sorted_verts)))[0]\n",
    "#     unique_split, offset_idx = np.unique(splitter, return_index=True)\n",
    "#     filtered = unique_split[(unique_split>0)&(unique_split<len(sorted_verts))]\n",
    "#     if len(offset_idx) == len(filtered) + 2:\n",
    "#         offset_idx = offset_idx[:-1]\n",
    "#     if len(filtered) == 0:\n",
    "#         offset_idx[:] = len(splitter) - 1\n",
    "#     split = np.array(np.split(sorted_verts, filtered))\n",
    "\n",
    "#     offset_idx.shape, unique_split.shape, filtered.shape, split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.2 ms ± 275 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "# side_length = 10000\n",
    "\n",
    "# self._offset = side_length\n",
    "# bbox = self.bbox\n",
    "# # Get the number of voxels to be used to create cubes (allowing for pushing past the boundaries).\n",
    "# num_voxels = np.ceil((np.abs(np.subtract(*bbox.T) / side_length))).astype(int)\n",
    "\n",
    "# # Create the cube voxel grid split structure. Could also sort the vertices according to the grid at this point?\n",
    "# start_coord = bbox.T[0]\n",
    "# cube_friendly_bbox = np.vstack((start_coord, start_coord + (num_voxels * side_length))).T\n",
    "# x_edges, y_edges, z_edges = [np.arange(minimum, maximum, side_length) for minimum, maximum in cube_friendly_bbox]\n",
    "\n",
    "x_split = apply_split(*examp_1) # self.vertices, x_edges, 0\n",
    "\n",
    "x_split[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.1 ms ± 252 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "np.array(apply_split(*examp_1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 278 ms, sys: 6.94 ms, total: 285 ms\n",
      "Wall time: 283 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "side_length = 2048\n",
    "\n",
    "self._offset = side_length\n",
    "bbox = self.bbox\n",
    "# Get the number of voxels to be used to create cubes (allowing for pushing past the boundaries).\n",
    "num_voxels = np.ceil((np.abs(np.subtract(*bbox.T) / side_length))).astype(int)\n",
    "\n",
    "# Create the cube voxel grid split structure. Could also sort the vertices according to the grid at this point?\n",
    "start_coord = bbox.T[0]\n",
    "cube_friendly_bbox = np.vstack((start_coord, start_coord + (num_voxels * side_length))).T\n",
    "x_edges, y_edges, z_edges = [np.arange(minimum, maximum, side_length) for minimum, maximum in cube_friendly_bbox]\n",
    "\n",
    "offset_vectors = list()\n",
    "offset_to_vertices = dict()\n",
    "\n",
    "x_split = np.array(self.apply_split(self.vertices, x_edges, 0)).T\n",
    "\n",
    "for x_id, x_block in x_split:\n",
    "    y_split = np.array(self.apply_split(x_block, y_edges, 1)).T\n",
    "    \n",
    "    for y_id, y_block in y_split:\n",
    "        z_split = np.array(self.apply_split(y_block, z_edges, 2)).T\n",
    "        \n",
    "        for z_id, z_block in z_split:\n",
    "            key = (x_id, y_id, z_id)\n",
    "            offset_vectors.append(key)\n",
    "            offset_to_vertices[key] = z_block\n",
    "\n",
    "offset_vectors = np.array(offset_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
