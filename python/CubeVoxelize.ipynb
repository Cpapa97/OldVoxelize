{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipyvolume.pylab as p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting cpapadop@10.28.0.34:3306\n"
     ]
    }
   ],
   "source": [
    "ta3p100 = dj.create_virtual_module('ta3p100', 'microns_ta3p100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetched_mesh = (ta3p100.Mesh & ta3p100.CurrentSegmentation & 'segment_id=648518346341351503').fetch1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetched_mesh = ta3p100.Decimation35.fetch(limit=1, as_dict=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetched_mesh = (ta3p100.Mesh & ta3p100.CurrentSegmentation & 'segment_id=648518346341366885').fetch1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Voxel:\n",
    "    def __init__(self, vertices):\n",
    "        self._vertices = vertices.copy()\n",
    "        \n",
    "    @property\n",
    "    def vertices(self):\n",
    "        return self._vertices\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_bbox(vertices):\n",
    "        return np.array([(np.min(axis), np.max(axis)) for axis in vertices.T])\n",
    "        \n",
    "    @property\n",
    "    def bbox(self):\n",
    "        return self.get_bbox(self.vertices)\n",
    "    \n",
    "    @property\n",
    "    def _rectangular_idx(self):\n",
    "        X = [0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
    "        Y = [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0]\n",
    "        Z = [0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0]\n",
    "        return np.vstack((X, Y, Z))\n",
    "    \n",
    "    @property\n",
    "    def voxels(self):\n",
    "        return self._voxels\n",
    "    \n",
    "    @voxels.setter\n",
    "    def voxels(self, voxels):\n",
    "        self._voxels\n",
    "    \n",
    "    @property\n",
    "    def offset(self):\n",
    "        return self._offset\n",
    "    \n",
    "    @offset.setter\n",
    "    def offset(self, side_length):\n",
    "        self._offset = side_length\n",
    "    \n",
    "    @property\n",
    "    def structure(self):\n",
    "        return self._structure\n",
    "        \n",
    "    @structure.setter\n",
    "    def structure(self, structure):\n",
    "        self._structure = structure # I just store each voxel as an offset value vector.\n",
    "    \n",
    "    @property\n",
    "    def voxel_vertices(self):\n",
    "        return self._voxel_vertices\n",
    "    \n",
    "    @voxel_vertices.setter\n",
    "    def voxel_vertices(self, voxel_vertices):\n",
    "        self._voxel_vertices = voxel_vertices\n",
    "    \n",
    "    @property\n",
    "    def structure_to_bboxes(self):\n",
    "        voxel_min = self.bbox[:,0] + (self.structure * self.offset)\n",
    "        voxel_max = voxel_min + self.offset\n",
    "        return np.stack([voxel_min, voxel_max], axis=2)\n",
    "    \n",
    "    @property\n",
    "    def voxel_bboxes_to_drawable(self):\n",
    "        return self.structure_to_bboxes[:, np.arange(3), self._rectangular_idx.T].transpose(0, 2, 1)\n",
    "    \n",
    "    @property\n",
    "    def volume(self):\n",
    "        \"\"\"\n",
    "        Returns the estimation of volume based on the voxelization. Units are the same as the vertex input.\n",
    "        \"\"\"\n",
    "        return self.offset**3 * len(self.structure)\n",
    "    \n",
    "    # Could have a more configurable plotting function. Like you give the argument ['mesh', 'structure', 'mesh_bbox', etc.]\n",
    "    def plot_structure(self, voxel_count_offset=0, voxel_limit=None, use_centroids_instead=False, width=800, height=600):\n",
    "        p3.figure(width=width, height=height)\n",
    "        p3.plot_trisurf(*fetched_mesh['vertices'].T/1000, triangles=fetched_mesh['triangles'])#[:10000])\n",
    "        if use_centroids_instead:\n",
    "            centroids = mesh.structure_to_bboxes.mean(axis=2)\n",
    "            if voxel_limit is not None:\n",
    "                centroids = centroids[:1000]\n",
    "            p3.scatter(*centroids.T/1000, color='blue', marker='sphere', size=0.25)\n",
    "        else:\n",
    "            # Make it so voxel_limit can be larger \n",
    "            bboxes = self.voxel_bboxes_to_drawable\n",
    "            voxel_count = len(bboxes)\n",
    "            if voxel_count_offset >= voxel_count:\n",
    "                voxel_count_offset = voxel_count - 1\n",
    "            if voxel_limit is not None:\n",
    "                if voxel_limit < (voxel_count + voxel_count_offset):\n",
    "                    bboxes = bboxes[voxel_count_offset:voxel_count_offset+voxel_limit]\n",
    "                else:\n",
    "                    bboxes = bboxes[voxel_count_offset:]\n",
    "            for bbox in self.voxel_bboxes_to_drawable:\n",
    "                p3.plot(*bbox/1000, color='blue')\n",
    "        # Can make xyzlim stuck to the bboxes that are actually plotted.\n",
    "        p3.squarelim()\n",
    "        p3.show()\n",
    "    \n",
    "#     @structure.indexer\n",
    "#     def structure(self, index_tuple):\n",
    "#         return self.structure[index_tuple] # self._structure[index_tuple]\n",
    "\n",
    "#     def plot_voxels(self):\n",
    "#         # Scale and transpose\n",
    "#         center = [4, 4, 4];\n",
    "#         cubesize = 2;\n",
    "#         # Vertices for Line Cube. Order matters\n",
    "#         X = [0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
    "#         Y = [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0]\n",
    "#         Z = [0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0]\n",
    "#         # Example two cube matrix. Unit cube and one scaled/translated cube\n",
    "#         X1 = [X X*cubesize+center(1)];\n",
    "#         Y1 = [Y Y*cubesize+center(2)];\n",
    "#         Z1 = [Z Z*cubesize+center(3)];\n",
    "#         # Single plot command for all 'cube lines'\n",
    "#         plot3(X1,Y1,Z1);\n",
    "    \n",
    "    def plot_mesh(self, width=800, height=600):\n",
    "        p3.figure(width=width, height=height)\n",
    "        p3.plot_trisurf(*fetched_mesh['vertices'].T/1000, triangles=fetched_mesh['triangles'])\n",
    "        p3.plot(*np.array([axis[idx] for axis, idx in zip(self.bbox, self._rectangular_idx)])/1000, color='blue')\n",
    "        p3.squarelim()\n",
    "        p3.show()\n",
    "    \n",
    "    def plot_voxels(self, width=800, height=600):\n",
    "        rectangular_idx = self._rectangular_idx\n",
    "        p3.figure(width=width, height=height)\n",
    "        p3.plot_trisurf(*fetched_mesh['vertices'].T/1000, triangles=fetched_mesh['triangles'])\n",
    "        [p3.plot(*np.array([axis[idx] for axis, idx in zip(bbox, rectangular_idx)])/1000, color='blue') for bbox in self.voxels]\n",
    "        p3.squarelim()\n",
    "        p3.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sort_vertex_rows(vertices):\n",
    "        # This still might be slower.\n",
    "        a = vertices\n",
    "        a = a[a[:,2].argsort()] # First sort doesn't need to be stable.\n",
    "        a = a[a[:,1].argsort(kind='mergesort')]\n",
    "        a = a[a[:,0].argsort(kind='mergesort')]\n",
    "        return a\n",
    "    \n",
    "    def cube_voxelize(self, side_length):\n",
    "        self.offset = side_length\n",
    "        bbox = self.bbox\n",
    "        # Get the number of voxels to be used to create cubes (allowing for pushing past the boundaries).\n",
    "        num_voxels = np.ceil((np.abs(np.subtract(*bbox.T) / side_length))).astype(int)\n",
    "        \n",
    "        # Create the cube voxel grid split structure. Could also sort the vertices according to the grid at this point?\n",
    "        start_coord = bbox.T[0]\n",
    "        cube_friendly_bbox = np.vstack((start_coord, start_coord + (num_voxels * side_length))).T\n",
    "        x_edges, y_edges, z_edges = [np.arange(minimum, maximum, side_length) for minimum, maximum in cube_friendly_bbox]\n",
    "#         print([len(x_edges), len(y_edges), len(z_edges)])        \n",
    "        \n",
    "        # With this version, I am again missing a portion of it.\n",
    "        offset_vectors = list()\n",
    "        voxel_vertices = dict()\n",
    "        \n",
    "        sorted_idx = mesh.vertices.T[0].argsort()\n",
    "        x_verts = mesh.vertices[sorted_idx]\n",
    "        splitter = x_verts.T[0].searchsorted(x_edges)\n",
    "        x_split = np.split(x_verts, splitter)\n",
    "        for i, x_block in enumerate(x_split):\n",
    "            if len(x_block) > 0:\n",
    "                sorted_idx = x_block.T[1].argsort()\n",
    "                y_verts = x_block[sorted_idx]\n",
    "                splitter = y_verts.T[1].searchsorted(y_edges)\n",
    "                y_split = np.split(y_verts, splitter)\n",
    "                if len(y_split) > 0:\n",
    "                    for j, y_block in enumerate(y_split):\n",
    "                        if len(y_block) > 0:\n",
    "                            sorted_idx = y_block.T[2].argsort()\n",
    "                            z_verts = y_block[sorted_idx]\n",
    "                            splitter = z_verts.T[2].searchsorted(z_edges)\n",
    "                            z_split = np.split(z_verts, splitter)\n",
    "                            if len(z_split) > 0:\n",
    "                                for k, z_block in enumerate(z_split):\n",
    "                                    if len(z_block) > 0:\n",
    "                                        vector = (i, j, k)\n",
    "                                        offset_vectors.append(vector)\n",
    "                                        voxel_vertices[tuple(np.array(vector)-1)] = z_block\n",
    "                                        \n",
    "        self.structure = np.array(offset_vectors) - 1\n",
    "        self.voxel_vertices = voxel_vertices\n",
    "        \n",
    "        return self.structure\n",
    "    \n",
    "        sorted_verts = self._sort_vertex_rows(mesh.vertices)\n",
    "\n",
    "        splitter = sorted_verts[:,0].searchsorted(x_edges)\n",
    "        x_split = np.split(sorted_verts, splitter)\n",
    "        \n",
    "        splitter = sorted_verts[:,1].searchsorted(y_edges)\n",
    "        y_split = np.split(sorted_verts, splitter)\n",
    "        \n",
    "        splitter = sorted_verts[:,2].searchsorted(z_edges)\n",
    "        z_split = np.split(sorted_verts, splitter)\n",
    "        \n",
    "        offset_vectors = list()\n",
    "        \n",
    "        # Potentially can now do a combinatorial thing between all of them. Maybe for each pair do a set intersection?\n",
    "        # Well, I literally only care to see if there are any vertices at all at the intersection, then I'll return an offset vector for each voxel.\n",
    "        for i, x_block in enumerate(x_split):\n",
    "            # This way of doing combinatorial is very inefficient, should use a numpy.apply_across_axis or something once I verify it works first.\n",
    "            # Or I just go the way of doing the searchsorted with this loop and just keep track of the voxel indices using the same i, j, k\n",
    "            # btw pretty sure that i, j, k can be directly used as the offset vector indices.\n",
    "            for j, y_block in enumerate(y_split):\n",
    "                for k, z_block in enumerate(z_split):\n",
    "                    if len(set.intersection(x_block, y_block, z_block)): offset_vectors.append((i, j, k))\n",
    "        \n",
    "        offset_vectors = np.array(offset_vectors)\n",
    "        return offset_vectors\n",
    "        \n",
    "        # Tag the voxels that have vertices. Keep track of the structure offset indices. But should I also keep track of voxel ids? Probably not if\n",
    "        # I do it where each voxel just holds the offset.\n",
    "        \n",
    "        \n",
    "        # Could I tag vertices for each voxel? How expensive would that be, but it would be very easy and efficient querying and manipulating afterwords.\n",
    "        \n",
    "        # Query number of vertices in large chunks and then split down into the medium then 1-1 voxel resolution.\n",
    "        \n",
    "        # To get the indices of the vertex blocks with vertices, do ( BUT this doesn't actually work, but you get the idea )\n",
    "        # summed = vertex_blocks.sum(axis=whatever_works)\n",
    "        # idx = np.where(summed>0)\n",
    "        \n",
    "        # Will also need to have a voxel-level \"bbox\" where it re-corners (moves it to the topmost-leftmost corner, or some other corner) the starting\n",
    "        # voxel structure centroid (or corner coordinate, this decision affects from where the offset is calculated) to the location that agrees with the\n",
    "        # existing offset distance settings and then it should be able to easily add/subtract the offset change from the offset indices stored in the voxel\n",
    "        # offset vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try voxelizing a mesh with all of the spines removed using the labeled spines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = Voxel(fetched_mesh['vertices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6638071537017822\n",
      "12352\n",
      "12352000000000\n",
      "CPU times: user 666 ms, sys: 0 ns, total: 666 ms\n",
      "Wall time: 664 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "start = time.time()\n",
    "thing = mesh.cube_voxelize(1000) #2048 #2500\n",
    "print(time.time() - start), print(len(thing)), print(mesh.volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([355,   1, 119, ...,  20,   2,  87])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks = np.array([vertices for vertices in mesh.voxel_vertices.values()])\n",
    "block_lens = np.array([len(vertices) for vertices in blocks])\n",
    "block_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.161e+03, 5.480e+02, 3.840e+02, 2.680e+02, 1.820e+02, 1.610e+02,\n",
       "        1.330e+02, 1.190e+02, 8.900e+01, 9.800e+01, 8.500e+01, 4.500e+01,\n",
       "        5.000e+01, 3.300e+01, 2.600e+01, 1.500e+01, 1.100e+01, 6.000e+00,\n",
       "        2.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
       "        1.000e+00]),\n",
       " array([1.0000e+00, 8.3200e+01, 1.6540e+02, 2.4760e+02, 3.2980e+02,\n",
       "        4.1200e+02, 4.9420e+02, 5.7640e+02, 6.5860e+02, 7.4080e+02,\n",
       "        8.2300e+02, 9.0520e+02, 9.8740e+02, 1.0696e+03, 1.1518e+03,\n",
       "        1.2340e+03, 1.3162e+03, 1.3984e+03, 1.4806e+03, 1.5628e+03,\n",
       "        1.6450e+03, 1.7272e+03, 1.8094e+03, 1.8916e+03, 1.9738e+03,\n",
       "        2.0560e+03]),\n",
       " <a list of 25 Patch objects>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(block_lens, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1271, 3419)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(block_lens[block_lens<100]), len(block_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2148"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh.structure = mesh.structure[(block_lens>=100)]\n",
    "len(mesh.structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d70dadd9eb474eaf23ccc2f8a38b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mesh.plot_structure(use_centroids_instead=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  37,  20],\n",
       "       [  0,  37,  21],\n",
       "       [  0,  38,  20],\n",
       "       ...,\n",
       "       [107,  79,  35],\n",
       "       [107,  80,  34],\n",
       "       [107,  80,  35]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start looking about how to standardize access to the structure.\n",
    "# I want a very consistent and stable structure.\n",
    "\n",
    "st = mesh.structure.copy()\n",
    "\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From there I need to start being able to compute several sets of statistics on the voxelization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Voxels:\n",
    "    def __init__(self, origin, side_length, offset_vectors=None):\n",
    "        \"\"\"\n",
    "        :param origin: The starting location of which the voxels will be offset from.\n",
    "        :param side_length: The length of a side of a voxel (they are cubes).\n",
    "        :param offset_vectors: The structure that stores the locations of the voxels as offset integers from the origin (using the side length as the increment).\n",
    "        \"\"\"\n",
    "        self.origin = origin\n",
    "        self.side_length = side_length\n",
    "        if offset_vectors is not None:\n",
    "            self.offset_vectors = offset_vectors\n",
    "        \n",
    "    @property\n",
    "    def origin(self):\n",
    "        return np.array((self._x, self._y, self._z))\n",
    "    \n",
    "    @origin.setter\n",
    "    def origin(self, coordinate):\n",
    "        self._x, self._y, self._z = coordinate\n",
    "        \n",
    "    @property\n",
    "    def side_length(self):\n",
    "        return self._side_length\n",
    "    \n",
    "    @side_length.setter\n",
    "    def side_length(self, side_length):\n",
    "        self._side_length = side_length\n",
    "        \n",
    "    @property\n",
    "    def offset_vectors(self):\n",
    "        return self._offset_vectors\n",
    "    \n",
    "    @offset_vectors.setter\n",
    "    def offset_vectors(self, offset_vectors):\n",
    "        if offset_vectors.shape == (len(offset_vectors), 3):\n",
    "            self._offset_vectors = offset_vectors\n",
    "        else:\n",
    "            raise TypeError(\"Array shape is incorrect, should be equivalent to (-1, 3).\")\n",
    "            \n",
    "            \n",
    "    # Maybe I should make this search_by_offset pretty extensible by some design? Like allow you to easily search by a bunch of x offsets,\n",
    "    # or even all of them. And also still be able to search for a certain offset like (0, 37, 20). Basically be able to search for a row,\n",
    "    # or from a column or a bunch of columns or for a bunch of rows, etc.\n",
    "    \n",
    "#     def search_by_offset(self, x_offset, y_offset, z_offset):\n",
    "#         return np.where((vs.offset_vectors==(x_offset, y_offset, z_offset)).all(axis=1))[0]\n",
    "    def search_by_offset(self, key):\n",
    "        print(type(self.offset_vectors==key))\n",
    "        return np.where((self.offset_vectors==key).all(axis=1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = Voxels(np.zeros(3, int), 10) # Should allow to use the precision of integers across the whole thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.offset_vectors = thing.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = (0, 37, 20)\n",
    "vs.search_by_offset(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-3a35bafbaa99>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-3a35bafbaa99>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    keys =\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "keys = \n",
    "vs.search_by_offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((vs.offset_vectors==key).all(axis=1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Iterable\n",
    "l = [1, 2, 3, 4]\n",
    "print(isinstance(l, Iterable))\n",
    "\n",
    "# This can be finished after the vector storing stuff is done.\n",
    "def search(x_offset=None, y_offset=None, z_offset=None):\n",
    "    \"\"\"\n",
    "    The purpose of this function is to standardize access to the voxel structure and be able to access voxels even if the number of entries in the structure changes.\n",
    "    \"\"\"\n",
    "    # Essentially they should be able to enter in any combination of x_offset, y_offset, and z_offset to return the index from a structure that can then be used\n",
    "    # to access a voxel or many voxels.\n",
    "    # If they give an x_offset and a z_offset then it should find all voxels with that have both that x_offset and z_offset (so the only thing that'll differ\n",
    "    # is the y_offset).\n",
    "    # Is it worth it to allow them to input say, several x_offsets and then have it be combinatorial if the number of y_offsets differ?\n",
    "    # Perhaps make it be an option that they have to explicitly choose. So either it'll expect at most a list of offset vectors, and if the lengths differ\n",
    "    # (besides the case where an offset is still set as None) then it'll raise an exception and ask if they wanted the combinatorial (factorization) option.\n",
    "    \n",
    "    try:\n",
    "        key = dict()\n",
    "        key['x'] = x_offset, y=y_offset, z=z_offset\n",
    "        \n",
    "        single_voxel_flag = True\n",
    "        # Do it the simple way first.\n",
    "        if x_offset is None:\n",
    "            single_voxel_flag = False\n",
    "        if y_offset is None:\n",
    "            single_voxel_flag = False\n",
    "        if z_offset is None:\n",
    "            single_voxel_flag = False\n",
    "        \n",
    "        if single_voxel_flag:\n",
    "            idx = np.where((vs.offset_vector==key).all(axis=1))[0]\n",
    "        \n",
    "        if key is not np.ndarray:\n",
    "            key = np.array(key)\n",
    "        \n",
    "        shape = key.shape\n",
    "        \n",
    "        if len(shape) > 0:\n",
    "#             if shape[0] > 3:\n",
    "            idx = np.where((vs.offset_vector==key).all(axis=1))[0]\n",
    "        \n",
    "        if shape == (len(key),)\n",
    "            idx = np.where((vs.offset_vectors==key).all(axis=1))[0]\n",
    "        elif key.shape\n",
    "            \n",
    "        return idx\n",
    "    except Exception as e:\n",
    "        Print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]), array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key1 = (0, 37, 20)\n",
    "key2 = (1)\n",
    "key3 = (3, 4, np.nan)\n",
    "search(key1), search(key2), search(key3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.array(key2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(key1).shape == (len(key1),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape, key_length = np.array(key1).shape, len(key1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(shape)\n",
    "print(key_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out how to use networkx for the mesh segmentation I want.\n",
    "# Maybe would be possible to do what I need to directly on the vertex neighborhood (requires vertices and triangles to generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_node((tuple(eh) for eh in thing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_node(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdjacencyView({<generator object <genexpr> at 0x7fa9183ac9e8>: {}, 0: {}})"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @schema if schema = dj.schema('microns_ta3p100')\n",
    "class VoxelConfig(dj.Lookup):\n",
    "    definition = \"\"\"\n",
    "    side_length   : decimal(10, 5)\n",
    "    ---\n",
    "    # side_length : float # hmm, I wanted the side length to be something I can use. Maybe I should force them to be integers or decimal? Yeah decimal\n",
    "                        # would actually pretty helpful.\n",
    "    \"\"\"\n",
    "    \n",
    "class Voxels(dj.Computed):\n",
    "    definition = \"\"\"\n",
    "    -> ta3p100.Mesh\n",
    "    -> VoxelConfig\n",
    "    \"\"\"\n",
    "    \n",
    "    key_source = ta3p100.Mesh * VoxelConfig\n",
    "    \n",
    "    class Structure(dj.Part):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outdated\n",
    "\n",
    "sorted_idx = nonisolated_vertices.T[0].argsort()\n",
    "x_verts = nonisolated_vertices[sorted_idx]\n",
    "splitter = x_verts.T[0].searchsorted(x_edges)\n",
    "x_split = np.split(x_verts, splitter)\n",
    "for x_block in x_split:\n",
    "    if len(x_block) > 0:\n",
    "        sorted_idx = x_block.T[1].argsort()\n",
    "        y_verts = x_block[sorted_idx]\n",
    "        splitter = y_verts.T[1].searchsorted(y_edges)\n",
    "        y_split = np.split(y_verts, splitter)\n",
    "        if len(y_split) > 0:\n",
    "            for y_block in y_split:\n",
    "                if len(y_block) > 0:\n",
    "                    sorted_idx = y_block.T[2].argsort()\n",
    "                    z_verts = y_block[sorted_idx]\n",
    "                    splitter = z_verts.T[2].searchsorted(z_edges)\n",
    "                    z_split = np.split(z_verts, splitter)\n",
    "                    if len(z_split) > 0:\n",
    "                        for z_block in z_split:\n",
    "                            if len(z_block) > 0:\n",
    "                                bboxes.append(self.get_bbox(z_block))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
